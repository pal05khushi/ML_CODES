# -*- coding: utf-8 -*-
"""logistic_regression_mds

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6lhpHKm9GtQxOZcz0FmHnvhsWWx6EI6
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix

np.random.seed(42)
data = {
    'Feature1': np.random.randn(100),
    'Feature2': np.random.randn(100),
    'Label': np.random.randint(0, 2, 100)
}
dataset = pd.DataFrame(data)

X = dataset[['Feature1', 'Feature2']].values
y = dataset['Label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

def logistic_regression_mds(X, y, learning_rate=0.01, iterations=1000):
    m, n = X.shape
    weights = np.zeros(n)
    bias = 0

    def sigmoid(z):
        return 1 / (1 + np.exp(-z))

    for _ in range(iterations):
        linear_model = np.dot(X, weights) + bias
        y_pred = sigmoid(linear_model)

        dw = (1 / m) * np.dot(X.T, (y_pred - y))
        db = (1 / m) * np.sum(y_pred - y)

        weights -= learning_rate * dw
        bias -= learning_rate * db

    return weights, bias

def predict(X, weights, bias):
    def sigmoid(z):
        return 1 / (1 + np.exp(-z))

    linear_model = np.dot(X, weights) + bias
    y_pred = sigmoid(linear_model)
    return np.array([1 if i > 0.5 else 0 for i in y_pred])

weights, bias = logistic_regression_mds(X_train_scaled, y_train)

y_pred_custom = predict(X_test_scaled, weights, bias)

accuracy_custom = accuracy_score(y_test, y_pred_custom)
conf_matrix_custom = confusion_matrix(y_test, y_pred_custom)

print(f"\nCustom Logistic Regression Model Accuracy: {accuracy_custom * 100:.2f}%")
print(f"Custom Confusion Matrix:\n{conf_matrix_custom}")

