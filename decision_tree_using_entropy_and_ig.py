# -*- coding: utf-8 -*-
"""decision tree using entropy and ig.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BY_jbWxworm3IGRk3hmOaYxc7wtEBYfp
"""

import numpy as np
import pandas as pd
from collections import Counter


data = [['Sunny', 'Hot', 'High', 'Weak', 'No'],
        ['Sunny', 'Hot', 'High', 'Strong', 'No'],
        ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],
        ['Rainy', 'Mild', 'High', 'Weak', 'Yes'],
        ['Rainy', 'Cool', 'Normal', 'Weak', 'Yes'],
        ['Rainy', 'Cool', 'Normal', 'Strong', 'No'],
        ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],
        ['Sunny', 'Mild', 'High', 'Weak', 'No'],
        ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],
        ['Rainy', 'Mild', 'Normal', 'Weak', 'Yes'],
        ['Sunny', 'Hot', 'High', 'Weak', 'No'],
        ['Sunny', 'Cool', 'High', 'Strong', 'No'],
        ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],
        ['Overcast', 'Mild', 'Normal', 'Weak', 'Yes'],
        ['Rainy', 'Mild', 'High', 'Strong', 'No'],
        ['Overcast', 'Mild', 'High', 'Weak', 'Yes'],
        ['Rainy', 'Cool', 'High', 'Weak', 'Yes'],
        ['Sunny', 'Mild', 'Normal', 'Weak', 'Yes'],
        ['Sunny', 'Mild', 'Normal', 'Strong', 'No']]

columns = ['Outlook', 'Temperature', 'Humidity', 'Wind', 'PlayTennis']
df = pd.DataFrame(data, columns=columns)


def entropy(y):
    counts = Counter(y)
    total = len(y)
    return -sum((count/total) * np.log2(count/total) for count in counts.values())


def information_gain(df, feature, target):
    total_entropy = entropy(df[target])
    values, counts = np.unique(df[feature], return_counts=True)
    weighted_entropy = sum((counts[i]/sum(counts)) * entropy(df[df[feature] == values[i]][target]) for i in range(len(values)))
    return total_entropy - weighted_entropy


def build_tree(df, target, features):
    if len(np.unique(df[target])) == 1:
        return df[target].iloc[0]
    if not features:
        return Counter(df[target]).most_common(1)[0][0]

    best_feature = max(features, key=lambda feature: information_gain(df, feature, target))
    tree = {best_feature: {}}

    for value in np.unique(df[best_feature]):
        sub_df = df[df[best_feature] == value].drop(columns=[best_feature])
        tree[best_feature][value] = build_tree(sub_df, target, [f for f in features if f != best_feature])

    return tree


decision_tree = build_tree(df, 'PlayTennis', list(df.columns[:-1]))
print(decision_tree)

